{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.applications import VGG16,VGG19\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.misc import imread, imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_im_cv2(path, img_rows, img_cols, color_type=3):\n",
    "    # Load as grayscale\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, 0)\n",
    "    elif color_type == 3:\n",
    "        img = cv2.imread(path)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train(img_rows, img_cols, color_type=3,num_files_to_read=-1):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    print('Read train images')\n",
    "    for j,target_type in enumerate['cat','dog']:\n",
    "        counter = 0\n",
    "        print('Load folder Type_{}'.format(j))\n",
    "        path = os.path.join('..', 'input', 'train',target_type+'*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im_cv2(fl, img_rows, img_cols, color_type)\n",
    "            X_train.append(np.asarray(img))\n",
    "            y_train.append(j)\n",
    "            counter+=1\n",
    "            if (counter>=num_files_to_read)&(num_files_to_read>0):\n",
    "                break\n",
    "    \n",
    "\n",
    "    return np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cache_data(data, path):\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('Directory doesnt exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 224\n",
    "img_cols = 224\n",
    "num_samples = -1\n",
    "read_from_cache = True\n",
    "color_type_global = 3\n",
    "if not read_from_cache:\n",
    "    X_train, y_train = load_train(img_rows,img_cols,3,num_samples)\n",
    "    cache_data(X_train,'../processed_input/X_train_{}X{}X{}_{}_max_samples'.format(img_rows,img_cols,\n",
    "                                                                                   color_type_global,num_samples))\n",
    "    cache_data(y_train,'../processed_input/y_train_{}_max_samples'.format(num_samples))\n",
    "else:    \n",
    "    X_train = restore_data('../processed_input/X_train_{}X{}X{}_{}_max_samples'.format(img_rows,img_cols,\n",
    "                                                                               color_type_global,num_samples))\n",
    "    y_train = restore_data('../processed_input/y_train_{}_max_samples'.format(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "#model = create_model(img_rows, img_cols, color_type_global)\n",
    "# Generate a model with all layers (with top)\n",
    "vgg16 = VGG16(weights='imagenet', include_top=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a layer where input is the output of the  second last layer \n",
    "x = (vgg16.layers[-4].output)\n",
    "\n",
    "#Then create the corresponding model \n",
    "model = Model(inputs=vgg16.input, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-5, momentum=0.95, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we are not going to train the model so we will not run the next line \n",
    "# it is only here for context of regular training / fine tuning of pretrained network\n",
    "#model.fit(X_train, to_categorical(y_train-1,3),validation_split=0.2,shuffle=True, batch_size=batch_size, epochs=epochs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
